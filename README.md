## ğŸŒ¡ Screenshot predict ì†Œê°œ

><b>ì‚¬ìš©ë²•</b><br>1. pneumonia, pneumothorax, ileus, pneumothorax ì¤‘ ëª¨ë“œ ì„ íƒ. <br>2. ìŠ¤í¬ë¦°ìƒ· ëª¨ë“œ(shift+ìœˆë„ìš°í‚¤+s)ì—ì„œ x-ray ë¶€ë¶„ë§Œ ì„ íƒ. <br>3. 'ìº¡ì³í•œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°' í´ë¦­ <br>4. 'ì˜ˆì¸¡ ë° í‘œì‹œ' í´ë¦­ <br>5. ì˜ˆì¸¡ ì™„ë£Œ í›„ ì¢Œì¸¡ ìƒë‹¨ì— ë¶„ë¥˜ í™•ë¥ ì´ 0.0 ~ 1.0 ì‚¬ì´ë¡œ í‘œì‹œë˜ë©° í•„ìš”ì‹œ ì €ì¥ê°€ëŠ¥

<br/>
<img width="850" alt="ì‹¤í–‰í™”ë©´" src="https://github.com/sensival/screenshot_predict/assets/136985426/cc2d919c-48f3-489f-951a-95d7be6c8547">


<hr>

## ğŸ’Œ Contributor

Development by: [@sensival](https://github.com/sensival/)<br>
Data Labeling by: Internal medicine R2 at SNUH

<hr>


## âš’ï¸ Development Tools

<br/>
<div align="left">
  <img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54"/>
  <img src="https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white"/>
</div\>

<br/>
<br>

><b> Pretrained model: </b>YOLOv8n-cls(https://docs.ultralytics.com/ko/models/yolov8/)<br><b>GUI: </b>tkinter(https://docs.python.org/3/library/tkinter.html)

<hr>

## ğŸ“ Dataset 

><b> Pneumonia dataset: </b>https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia<br><b>Pneumothorax dataset: </b>https://www.kaggle.com/datasets/vbookshelf/pneumothorax-chest-xray-images-and-masks<br><b>Ileus dataset: </b>Manual scraping and personally labeling the data <br><b>Pneumoperitoneum dataset: </b>Manual scraping and personally labeling the data <br>

|  | Pneumonia | Pneumothorax | Ileus | Pneumothorax |
| :-: |  :-: | :-: | :-: | :-: |
| Train | Disease: 3875 images <br> Normal: 1341  | Disease: 2379 images <br> Normal: 8296<br>  |  Disease: 51 images <br> Normal: 138<br> | Disease: 25 images <br> Normal: 188<br> |
| Validation | Disease: 8 images <br> Normal: 8  | The train data was divided(0.1)|  K-fold-cross-validation(k=10) | K-fold-cross-validation(k=10) |
| Test | Disease: 390 images <br> Normal: 234  | Disease: 390 images <br> Normal: 234|  Disease: 16 images <br> Normal: 11 | Disease: 5 images <br> Normal: 11 |

<hr>

## ğŸ‘‹ About YOLOv8
> YOLOv8 is the latest iteration in the YOLO series of real-time object detectors, offering cutting-edge performance in terms of accuracy and speed. The YOLOv8 series offers a diverse range of models, each specialized for specific tasks in computer vision. Additionally, these models are compatible with various operational modes including Inference, Validation, Training, and Export, facilitating their use in different stages of deployment and development.<br>

<img width="850" alt="YOLOì„±ëŠ¥" src="https://github.com/sensival/screenshot_predict/assets/136985426/ef2720dd-0c26-4f68-bb41-47118a2ddbe2">

#### YOLOv8n-cls is a model that uses fewer resources, has fast computational speed, and relatively lower accuracy. (This model was chosen because it needs to be trained on a personal computer.)

<br/>
<hr>

## âœï¸ Development Details

### Directory setting
The project's data directory is organized as follows:
- **pneumonia/**
  - **train/**
    - **NORMAL/**
    - **PNEUMONIA/**
  - **val/**
    - **NORMAL/**
    - **PNEUMONIA/**
  - **test/**
    - **NORMAL/**
    - **PNEUMONIA/**
- **pneumothorax/**
  - **train/**
    - **NORMAL/**
    - **PNEUMOTHORAX/**
  - **test/**
    - **NORMAL/**
    - **PNEUMOTHORAX/**
- **ileus/**
  - **train/**
    - **ILEUS/**
    - **NORMAL/**
  - **test/**
    - **ILEUS/**
    - **NORMAL/**
- **pnperi/** 
  - **train/**
    - **FREEAIR/**
    - **NORMAL/**  *'free air' : Pneumoperitoneum findings
  - **test/**
    - **FREEAIR/**
    - **NORMAL/**



### Train/Validation code

#### Pneumonia

```python
model.train(data=dataset_directory, 
            epochs=100, 
            imgsz=224, 
            project=output_directory, 
            name="pneumonia_detection", 
            save=True)
```

#### Pneumothorax
```python
model.train(data=dataset_directory, 
            epochs=100, 
            imgsz=224, 
            project=output_directory, 
            name="pneumothorax_detection", 
            save=True,
            split=0.1) # validation dataê°€ ë”°ë¡œ ì—†ì–´ì„œ split
```
#### Ileus/Pneumoperitoneum(k-fold)
```python
# ------- : ILEUS or FRESSAIR
k = 10
kf = KFold(n_splits=k)

fold_idx = 0
for train_index, test_index in kf.split(data):
    # ê° í´ë“œë³„ë¡œ ë°ì´í„° ë¶„í• 
    train_data, test_data = [data[i] for i in train_index], [data[i] for i in test_index]
    train_labels, test_labels = [labels[i] for i in train_index], [labels[i] for i in test_index]

    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    train_dir = 'tempo/train'
    val_dir = 'tempo/val'
    
    if not os.path.exists(train_dir):
        os.makedirs(os.path.join(train_dir, '-------'))
        os.makedirs(os.path.join(train_dir, 'NORMAL'))
    if not os.path.exists(val_dir):
        os.makedirs(os.path.join(val_dir, 'ILEUS'))
        os.makedirs(os.path.join(val_dir, 'NORMAL'))
    
    # í•™ìŠµ ë°ì´í„° ë³µì‚¬
    for img, label in zip(train_data, train_labels):
        label_dir = '-------' if label == 0 else 'NORMAL'
        shutil.copy(img, os.path.join(train_dir, label_dir, os.path.basename(img)))
    
    # ê²€ì¦ ë°ì´í„° ë³µì‚¬
    for img, label in zip(test_data, test_labels):
        label_dir = '-------' if label == 0 else 'NORMAL'
        shutil.copy(img, os.path.join(val_dir, label_dir, os.path.basename(img)))

    # ëª¨ë¸ í•™ìŠµ
    model.train(data='tempo', 
                epochs=10,
                imgsz=224, 
                project=output_directory, 
                name=f"-------_detection_fd{fold_idx+1}_", 
                save=True)

    # ëª¨ë¸ ê²€ì¦
    results = model.val()

    # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
    shutil.rmtree('tempo')
    fold_idx += 1
```


### Test code
```python
# ------- : Condition name
# best ëª¨ë¸ dir
best_dir =()
model = YOLO("best_dir")

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
test_images = []
test_labels = []

for label in ['NORMAL', '-------']:
    class_path = os.path.join(test_folder, label)
    for img_name in os.listdir(class_path):
        img_path = os.path.join(class_path, img_name)
        test_images.append(img_path)
        test_labels.append(label)

results_test = model(test_images)

# ì˜ˆì¸¡ ë ˆì´ë¸” ìˆ˜ì§‘
test_preds = [result.probs.top1 for result in results_test]  # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ì„ íƒ
test_cls = [['NORMAL', '-------'][i] for i in test_preds]

# ì •í™•ë„ ê³„ì‚°
accuracy = accuracy_score(test_labels, test_cls)
print(f"Test Accuracy: {accuracy:.4f}")

# ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„±
report = classification_report(test_labels, test_cls, target_names=['NORMAL', '-------'])
print("\nClassification Report:\n", report)
with open(output_directory+'/classification_report_-------.txt', 'w') as f:
    f.write(report)

# confusion_matrix ìƒì„±
cm = confusion_matrix(test_labels, test_cls)
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['normal', '-------'], yticklabels=['normal', '-------'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.savefig(output_directory+'/confusion_matrix_-------.png')
```

### GUI
[Refer to the source code](https://github.com/sensival/screenshot_predict/blob/main/xr_predict.py)<br>

### Result
#### Pneumonia
<img width="500" alt="pmn tr" src="https://github.com/sensival/screenshot_predict/assets/136985426/69e3fbc0-192a-4975-aa2d-d2f0b057ed0c"><br>

Due to the small size of the validation dataset, it was difficult to determine the point of overfitting, so it was trained for an additional 100 epochs.<br>
<img width="500" alt="pmn tr" src="https://github.com/sensival/screenshot_predict/assets/136985426/9ce6e541-4732-4de5-933b-c9e8fefeffec"><br>
The validation results are still unstable. It needs to increase the size of the validation dataset in the future<br>

<br/>
<hr/>
